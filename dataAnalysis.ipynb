{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import Series, DataFrame\n",
    "import sqlalchemy\n",
    "from sqlalchemy import create_engine,Table,Column,Integer,String,MetaData,ForeignKey,Date,update\n",
    "import warnings\n",
    "from IPython.display import display\n",
    "import io\n",
    "import os\n",
    "\n",
    "from nltk.parse.stanford import StanfordDependencyParser\n",
    "\n",
    "#os.environ[\"JAVA_HOME\"] = \"/Library/Java/JavaVirtualMachines/jdk1.8.0_25.jdk/Contents/Home\" \n",
    "#os.environ[\"CLASSPATH\"] = \"/home/chweng/Desktop/SemanticProj/StanfordNLP/jars\"\n",
    "#os.environ[\"STANFORD_MODELS\"] = \"/home/chweng/Desktop/SemanticProj/StanfordNLP/models\"\n",
    "os.environ[\"CLASSPATH\"] ='/Users/chweng/Desktop/StanfordNLP/jars'\n",
    "os.environ[\"STANFORD_MODELS\"] ='/Users/chweng/Desktop/StanfordNLP/models'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def load_csv(date):\n",
    "    #載入資料庫抓下來的csv檔存成pandas dataframe\n",
    "    df=pd.DataFrame.from_csv(\"data/reviews-%s.csv\"%(date), encoding=\"utf-8\",index_col=None)\n",
    "    #.reset_index(drop=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def summary(df):\n",
    "    #確認資料數\n",
    "    prodTypes=[\"central\",\"canister\",\"handheld\",\"robotic\",\"stick\",\"upright\",\"wetdry\"]\n",
    "    #choose type\n",
    "    for prodType in prodTypes:\n",
    "        print(prodType,len(df.loc[df[\"ptype\"]==prodType][\"review\"]))\n",
    "    print(\"total reviews=\",len(df),\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def store_prodRevs_in_a_list(prodType,df):\n",
    "    '''將pandas dataframe內的評論提取，存成一個List。該List\n",
    "    '''\n",
    "    df=df.loc[df[\"ptype\"]==prodType]\n",
    "    pReviewsGroup=df.groupby(['ptype','pid'])\n",
    "\n",
    "    reviews_list=[]\n",
    "    for key,pReviews in pReviewsGroup:\n",
    "        rids=pReviews[[\"rid\",\"review\"]].values[:,0].tolist()\n",
    "        reviews=pReviews[[\"rid\",\"review\"]].values[:,1].tolist()\n",
    "\n",
    "        ptypes=[key[0]]*len(rids)\n",
    "        pids=[key[1]]*len(rids)\n",
    "        reviews_list+=list(zip(ptypes,pids,rids,reviews))\n",
    "\n",
    "    print(\"number of products=\",len(pReviewsGroup))\n",
    "    print(\"number of reviews in type %s=%i\"%(prodType,len(reviews_list)))\n",
    "    \n",
    "    return reviews_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def cleanText(review):\n",
    "    #print(len(review))\n",
    "    review=review.lower().replace('\\n','').replace(';',',').replace('!',',') \\\n",
    "                 .replace('i.e.','').strip()\n",
    "    review=re.sub(\"\\.+,\", \",\",review)     # replace ......., with ,\n",
    "    review=re.sub(\"\\.+\",\".\", review)      # replace ........ with .\n",
    "    review=re.sub(\"\\,+\",\",\", review)      # replace ,,,,,,,, with ,\n",
    "    review=re.sub('[\\\"\\'\\*]','', review)  # remove \", ' and *\n",
    "    \n",
    "    #remove emoji\n",
    "    emoji_pattern = re.compile(\"[\"  \n",
    "        u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "        u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "        u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "        u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                           \"]+\", flags=re.UNICODE)\n",
    "    review=re.sub(emoji_pattern,\"\", review)\n",
    "    review=re.sub('(?::|;|=)(?:-)?(?:\\)|\\(|D|P)',\"\",review)\n",
    "    # notice that, the question mark makes the preceding token\n",
    "    # in the regular expression optional.\n",
    "    # also, (?: xxx) is a non-capturing group\n",
    "    # let us probably come back to this re later.\n",
    "    return review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def splitSentences(review):\n",
    "    rev=re.split(r' *[\\.\\?!][\\'\"\\)\\]]* *', review)\n",
    "    return rev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def reviewsProcessing(reviews_list):\n",
    "    reviews_list=[(review[0],review[1],review[2],splitSentences(cleanText(review[3])))\n",
    "                              for review in reviews_list if review[3]==review[3]]\n",
    "    return reviews_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def extractSentencesOfTheSelectedReviews(prodIDs,reviews_list):\n",
    "    # extract the sentences of the targeted products (those products are contained in the list: prodIDs)\n",
    "    buf = io.StringIO(prodIDs)\n",
    "    prodIDs=buf.readlines()\n",
    "    prodIDs=list(map(lambda x:re.sub('[\\n]','',x) ,prodIDs))\n",
    "    selectedReviews=[review[3] for review in reviews_list if(review[1] in prodIDs)]\n",
    "    sentences=[sentence for sentences in selectedReviews for sentence in sentences]\n",
    "    print(\"number of sentences from the selected prodIDs %s=%i\"%(prodIDs,len(sentences)))\n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def findMatchedSentences(pattern,sentences):\n",
    "    sentsMatched=[sentence for sentence in sentences if pattern in sentence]\n",
    "    print(\"number of the sentences matched the pattern '%s'=%i\"%(pattern,len(sentences)))\n",
    "    return sentsMatched\n",
    "   \n",
    "#    for idx,sentence in enumerate(sentences):\n",
    "#        if('suction' in sentence):\n",
    "#            print(idx,repr(sentence),'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "central 335\n",
      "canister 23294\n",
      "handheld 79899\n",
      "robotic 26944\n",
      "stick 57268\n",
      "upright 102643\n",
      "wetdry 16821\n",
      "total reviews= 307204 \n",
      "\n",
      "number of products= 350\n",
      "number of reviews in type canister=23294\n",
      "number of sentences from the selected prodIDs ['B00002N8CX']=14427\n",
      "number of the sentences matched the pattern 'noise'=14427\n"
     ]
    }
   ],
   "source": [
    "#product types\n",
    "prodTypes=[\"central\",\"canister\",\"handheld\",\"robotic\",\"stick\",\"upright\",\"wetdry\"]\n",
    "\n",
    "df=load_csv(\"2017-02-03\")                               # load reviews from csv\n",
    "summary(df)\n",
    "reviews_list=store_prodRevs_in_a_list(prodTypes[1],df)  # store reviews into a list\n",
    "reviews_list=reviewsProcessing(reviews_list)            # the sentences of the reviews are cleaned\n",
    "\n",
    "#product id\n",
    "prodIDs='''B00002N8CX\n",
    "'''                        \n",
    "#prodIDs='''B00002N8CX\n",
    "#B00AZBIXHG\n",
    "#B00AZBIV9Q\n",
    "#'''\n",
    "\n",
    "# obtain all the sentences of the reviews of the selected products\n",
    "sentences=extractSentencesOfTheSelectedReviews(prodIDs,reviews_list)\n",
    "\n",
    "sentsMatched=findMatchedSentences(\"noise\",sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the noise',\n",
       " 'it produces a powerful vacuum, easily maneuverable, convenient for storing, the noise is not too bad, and a good price',\n",
       " 'the noise isnt too painful, either (some  low-powered vacuums make that high-pitched whining noise that just makes  you want to live in filth)',\n",
       " 'it is higher-power, (better suction, but it blew a circuit the first time i used it), and the noise it makes is much louder than the old one',\n",
       " 'and if you can vacuum your home 2x faster, the noise lasts only half as long']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentsMatched[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### now, let's check if the Stanford parser works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'suction is not good at all' \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#sent='i found no neg_fault with the suction power, the machine picked up bits of paper and cat litter easily without multiple passes '\n",
    "sent='suction is not good at all'\n",
    "#sent='actually you don\\'t need a carpet attachment with this because it has so much suction'\n",
    "#sent='it costs too much money'\n",
    "print(repr(sent),'\\n')\n",
    "parser = StanfordDependencyParser()\n",
    "res = list(parser.parse(sent.split()))\n",
    "\n",
    "#for row in res[0].triples():\n",
    "#    print(row)\n",
    "\n",
    "rels=[rel for rel in res[0].triples()]\n",
    "   \n",
    "#for row in res[0].tree():\n",
    "#    if type(row) is not str:\n",
    "#        #row.draw()\n",
    "#        display(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(('good', 'JJ'), 'nsubj', ('suction', 'NN'))\n",
      "(('good', 'JJ'), 'cop', ('is', 'VBZ'))\n",
      "(('good', 'JJ'), 'neg', ('not', 'RB'))\n",
      "(('good', 'JJ'), 'nmod', ('all', 'DT'))\n",
      "(('all', 'DT'), 'case', ('at', 'IN'))\n"
     ]
    }
   ],
   "source": [
    "for rel in rels:\n",
    "    print(rel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-268-45e65b8f8227>, line 9)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-268-45e65b8f8227>\"\u001b[0;36m, line \u001b[0;32m9\u001b[0m\n\u001b[0;31m    if triple[1]='neg':\u001b[0m\n\u001b[0m                ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "for sent in sentsMatched[:1]:\n",
    "\n",
    "    parser = StanfordDependencyParser()\n",
    "    result = list(parser.parse(sent.split()))\n",
    "    rels=[rel for rel in result[0].triples()]\n",
    "\n",
    "    negList=['no','not']\n",
    "    for triple in rels:\n",
    "        if triple[1]='neg':\n",
    "            if triple[0][1] in negList:\n",
    "                \n",
    "    \n",
    "    \n",
    "    \n",
    "    depWords=[]\n",
    "    pattern='noise'\n",
    "\n",
    "    depPairs=[(rel[0][0],rel[2][0]) for rel in rels]\n",
    "    for depPair in depPairs:\n",
    "        if(pattern in depPair[0]):\n",
    "            depWords.append(depPair[1])\n",
    "        if(pattern in depPair[1]):\n",
    "            depWords.append(depPair[0])\n",
    "    print(sent,depWords,'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### todo: \n",
    "* find amod words for visualization \n",
    "* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the noise ['the'] \n",
      "\n",
      "it produces a powerful vacuum, easily maneuverable, convenient for storing, the noise is not too bad, and a good price ['bad,', 'the'] \n",
      "\n",
      "the noise isnt too painful, either (some  low-powered vacuums make that high-pitched whining noise that just makes  you want to live in filth) ['isnt', 'make', 'that', 'high-pitched', 'whining', 'makes'] \n",
      "\n",
      "it is higher-power, (better suction, but it blew a circuit the first time i used it), and the noise it makes is much louder than the old one ['louder', 'the', 'makes'] \n",
      "\n",
      "and if you can vacuum your home 2x faster, the noise lasts only half as long ['lasts', 'the'] \n",
      "\n",
      "unfortunately, the rest of the people in the house were subjected to airplane jet engine level noise ['unfortunately,', 'jet', 'engine', 'level'] \n",
      "\n",
      "con: the noise is unbearably loud ['loud', 'the'] \n",
      "\n",
      "my wife wouldnt let me keep it anyway because she said it makes a very loud high pitched noise ['makes', 'a', 'loud', 'high', 'pitched'] \n",
      "\n",
      "im okay with the noise as some vacuums are worse ['okay', 'with', 'the'] \n",
      "\n",
      "also, it does not make the high noise ['make', 'the', 'high'] \n",
      "\n",
      "according to other reviewers it is super loud but i find this to be untrue, vacuums make noise this is no louder then any other vacuum i have used ['make', 'louder'] \n",
      "\n",
      "the vacuum is powerful,but the noise of the motor is intolerable,to return it for credit costs about 40 percent of the total price ['is', 'the', 'motor'] \n",
      "\n",
      "we re going to give it to a young person who can tolerate the noise ['tolerate', 'the'] \n",
      "\n",
      "you have to pull on the hose and the minute theres a slight turn, the hose bends all the way and blocks the air, letting out a very loud noise that scared the neighbors dogs ['letting', 'a', 'loud', 'scared'] \n",
      "\n",
      "although some reviewers ciomplained about the noise, i dont share that complaint at all ['share'] \n",
      "\n",
      "i was worried about the noise, as i has seen a few complaints about that, but it was actually a lot quieter than expected, (but not the quietest vacuum of all time fyi if thats a requirement) ['worried', 'about', 'the'] \n",
      "\n",
      "the body warms noticeably and the noise is quite loud ['noticeably', 'the'] \n",
      "\n",
      "two cons:- the sound is like having an f-15 taking off inside your living room, so if you are a sensitive person to noise or you cant handle the vacuum while in a hangover, i would not buy this product ['cant', 'or', 'you'] \n",
      "\n",
      "my biggest complaint is the noise ['complaint', 'is', 'the'] \n",
      "\n",
      "it is very loud so i actually wore noise cancelling headphones while vacuuming ['headphones'] \n",
      "\n",
      "the motor is very well shock mounted which cut the noise down quite a bit ['cut', 'the'] \n",
      "\n",
      "the noise level is perfectly acceptable and way lower than our shopvac ['level'] \n",
      "\n",
      "some here have said it is too loud, yet it has about the same amount of noise as any good vacuum ['amount', 'of', 'vacuum'] \n",
      "\n",
      "intolerable noise level ['level'] \n",
      "\n",
      "the noise level of both units has the eureka putting out about twice the noise level of the bmc ['level', 'level'] \n",
      "\n",
      "i have to relate the sound to a pleasing purr instead of noise ['purr', 'instead'] \n",
      "\n",
      "it has great suction and the noise level is not too bad ['level'] \n",
      "\n",
      "the downside to this product is the immense loud noise ['downside', 'is', 'the', 'immense', 'loud'] \n",
      "\n",
      "and noise level is surprisingly low for the power ['level'] \n",
      "\n",
      "motor noise not as bad to me, but i havent bought a new vacuum in over 10 years, so i dont know if current models are that quieter ['bought', 'motor', 'bad'] \n",
      "\n",
      "the main issue we had was that the plastic made a grating noise on our polyurethaned hardwood floors ['made', 'a', 'grating', 'floors'] \n",
      "\n",
      "also it makes an inhuman noise, it is like having an airbus at home, i thought that the neighbors would actually come up and complain due to the incredible loudness of this vacuum cleaner ['makes', 'an', 'inhuman', 'having'] \n",
      "\n",
      "wish more attachments came with the modelmany have complained of the noise with this model ['complained', 'of', 'the', 'model'] \n",
      "\n",
      "if you would like a dust mop with a little extra power and a lot more noise, this vacuum is for you ['mop', 'more', 'you'] \n",
      "\n",
      "noise:  this vacuum is noisier than full size vacuums ['noisier'] \n",
      "\n",
      "if you and your animals do not mind the noise you will like this vacuum ['mind', 'the', 'like'] \n",
      "\n",
      "for all the noise it makes, this is a piece of junk ['makes,', 'for', 'all', 'the'] \n",
      "\n",
      "the down side is it is extremely loud, giving off a high pitched screeching noise that is very offensive to the ears ['giving', 'a', 'high', 'pitched', 'screeching', 'offensive'] \n",
      "\n",
      "~ what else can i say besides ~ im happy only thing is there is a odd noise when the vacuum is on ['is', 'a', 'odd', 'on'] \n",
      "\n",
      "the body warms noticeably and the noise is quite loud ['noticeably', 'the'] \n",
      "\n",
      "its cleans well but id choose another model due to noise and hose ['due', 'to', 'and', 'hose'] \n",
      "\n",
      "its only going to run for a little while so the noise should not be an issue ['issue', 'the'] \n",
      "\n",
      "it has excellent suction and the the noise level is reasonable ['level'] \n",
      "\n",
      "maybe i find loud noise more objectionable than most, but i think anyone buying this vacuum should invest in some kind of ear protection ['find', 'loud', 'objectionable'] \n",
      "\n",
      "the noise level is about the same, noisy ['level'] \n",
      "\n",
      "the reason for the four stars is because of the noise, but i would recommend the vacuum ['reason', 'is', 'because', 'the', 'recommend'] \n",
      "\n",
      "like some other reviewers, she says that it is rather loud, but that is acceptable since the noise is due to the power of the motor ['due', 'the'] \n",
      "\n",
      "the noise level is akin to a baby crying on an airplane, so wear some noise cancelling headphones or some earplugs while you clean ['level', 'wear', 'some', 'cancelling'] \n",
      "\n",
      "i highly recommend this item for its utility, but im downgrading one star based on the noise factor ['factor'] \n",
      "\n",
      "i gave 4/5 stars as the noise level is pretty deafening, but all else is great ['level'] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for sent in sentsMatched[:50]:\n",
    "\n",
    "    parser = StanfordDependencyParser()\n",
    "    result = list(parser.parse(sent.split()))\n",
    "    rels=[rel for rel in result[0].triples()]\n",
    "\n",
    "    depWords=[]\n",
    "    pattern='noise'\n",
    "\n",
    "    depPairs=[(rel[0][0],rel[2][0]) for rel in rels]\n",
    "    for depPair in depPairs:\n",
    "        if(pattern in depPair[0]):\n",
    "            depWords.append(depPair[1])\n",
    "        if(pattern in depPair[1]):\n",
    "            depWords.append(depPair[0])\n",
    "    print(sent,depWords,'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### codes grave yard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hahaha . . . '"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text=\"hahaha :) :( :D \"\n",
    "re.sub('(?::|;|=)(?:-)?(?:\\)|\\(|D|P)', \".\",text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'.ha'"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text=\"hahaha\"\n",
    "re.sub('(?:haha)', \".\",text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<_sre.SRE_Match object; span=(0, 4), match='haha'> \n",
      " ()\n"
     ]
    }
   ],
   "source": [
    "text=\"hahaha\"\n",
    "m=re.match('(?:haha)',text)\n",
    "print(m,\"\\n\",m.groups())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('1',)\n"
     ]
    }
   ],
   "source": [
    "text='1st'\n",
    "m=re.match('([0-9]+)(?:st|nd|rd|th)?',text)\n",
    "print(m.groups())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "text=\"hahaha :) :( :D \"\n",
    "m=re.match('(?::|;|=)(?:-)?(?:\\)|\\(|D|P)',text)\n",
    "print(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['aa', 'a'], ['bb', 'b']]"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=['aa|a','bb|b']\n",
    "\n",
    "def f(x):\n",
    "    return x.split(\"|\")\n",
    "\n",
    "list(map(f,a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Am I poor and vulnerable', \"My heart is turned and tossed, and it's all because of you.\"]\n"
     ]
    }
   ],
   "source": [
    "text = \"Am I poor and vulnerable ? My heart is turned and tossed..., and it's all because of you...\"\n",
    "text=re.sub(\"\\.+,\", \",\",text)\n",
    "text=re.sub(\"\\.+\", \".\",text)\n",
    "sentence = re.split(r' *[\\.\\?!][\\'\"\\)\\]]* +', text)\n",
    "print(sentence)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
